{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkZZvMrlNDNa/q3ZsFSyyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alpadedhia/ai-agents/blob/main/Langgraph_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGqQ5kHNiLdK"
      },
      "outputs": [],
      "source": [
        "pip install openai python-dotenv langchain langgraph langchain_openai langchain_community langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import re\n",
        "import httpx\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "_ = load_dotenv()\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "K_2EguUyiL7G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=\"\")"
      ],
      "metadata": {
        "id": "rM1bUqu-ierr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
        "\n",
        "tool = TavilySearchResults(max_results=4) #increased number of results\n",
        "print(type(tool))\n",
        "print(tool.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4dU9Lopij3z",
        "outputId": "ceaa53e1-6b58-462b-de81-d407c5e55fa7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
            "tavily_search_results_json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]"
      ],
      "metadata": {
        "id": "DgRdC-nZilBG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self, model, tools, system=\"\"):\n",
        "        self.system = system\n",
        "        graph = StateGraph(AgentState)\n",
        "        graph.add_node(\"llm\", self.call_openai)\n",
        "        graph.add_node(\"action\", self.take_action)\n",
        "        graph.add_conditional_edges(\n",
        "            \"llm\",\n",
        "            self.exists_action,\n",
        "            {True: \"action\", False: END}\n",
        "        )\n",
        "        graph.add_edge(\"action\", \"llm\")\n",
        "        graph.set_entry_point(\"llm\")\n",
        "        self.graph = graph.compile()\n",
        "        self.tools = {t.name: t for t in tools}\n",
        "        self.model = model.bind_tools(tools)\n",
        "\n",
        "    def exists_action(self, state: AgentState):\n",
        "        result = state['messages'][-1]\n",
        "        return len(result.tool_calls) > 0\n",
        "\n",
        "    def call_openai(self, state: AgentState):\n",
        "        messages = state['messages']\n",
        "        if self.system:\n",
        "            messages = [SystemMessage(content=self.system)] + messages\n",
        "        message = self.model.invoke(messages)\n",
        "        return {'messages': [message]}\n",
        "\n",
        "    def take_action(self, state: AgentState):\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            print(f\"Calling: {t}\")\n",
        "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
        "                print(\"\\n ....bad tool name....\")\n",
        "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
        "            else:\n",
        "                result = self.tools[t['name']].invoke(t['args'])\n",
        "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "        print(\"Back to the model!\")\n",
        "        return {'messages': results}\n",
        "\n",
        "# prompt = \"\"\"\n",
        "# You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "# At the end of the loop you output an Answer\n",
        "# Use Thought to describe your thoughts about the question you have been asked.\n",
        "# Use Action to run one of the actions available to you - then return PAUSE.\n",
        "# Observation will be the result of running those actions.\n",
        "\n",
        "# Your available actions are:\n",
        "\n",
        "# calculate:\n",
        "# e.g. calculate: 4 * 7 / 3\n",
        "# Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "# average_dog_weight:\n",
        "# e.g. average_dog_weight: Collie\n",
        "# returns average weight of a dog when given the breed\n",
        "\n",
        "# Example session:\n",
        "\n",
        "# Question: How much does a Bulldog weigh?\n",
        "# Thought: I should look the dogs weight using average_dog_weight\n",
        "# Action: average_dog_weight: Bulldog\n",
        "# PAUSE\n",
        "\n",
        "# You will be called again with this:\n",
        "\n",
        "# Observation: A Bulldog weights 51 lbs\n",
        "\n",
        "# You then output:\n",
        "\n",
        "# Answer: A bulldog weights 51 lbs\n",
        "# \"\"\".strip()\n",
        "\n",
        "\n",
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=\"\")  #reduce inference cost\n",
        "abot = Agent(model, [tool], system=prompt)\n",
        ""
      ],
      "metadata": {
        "id": "lPYjeSQhkK5F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
        "result = abot.graph.invoke({\"messages\": messages})\n",
        "\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "YpZ9T4OcYPdS",
        "outputId": "a67b8967-cda2-4026-e8ff-c6dafc117451"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_NCeqeLHgqvJO8nH2u0kkiCxn', 'type': 'tool_call'}\n",
            "Back to the model!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current weather in San Francisco is partly cloudy with a temperature of 64.0°F (17.8°C). The wind speed is 3.1 mph (5.0 kph) coming from the north-northeast direction. The humidity is at 78%, and there is no precipitation at the moment.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
        "What is the GDP of that state? Answer each question.\"\n",
        "messages = [HumanMessage(content=query)]\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\", api_key=\"\")  # requires more advanced model\n",
        "abot = Agent(model, [tool], system=prompt)\n",
        "result = abot.graph.invoke({\"messages\": messages})\n",
        "\n",
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "wp4m9DQqYuP_",
        "outputId": "d0a1fbf6-6761-433f-9a6b-c6648e7cbdcd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Super Bowl winner 2024'}, 'id': 'call_qpB3omgzD2TVLIm9LIKvAYjA', 'type': 'tool_call'}\n",
            "Back to the model!\n",
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'call_lY5pqruTxHabPCNGKfh0hFtk', 'type': 'tool_call'}\n",
            "Back to the model!\n",
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current GDP of Missouri 2024'}, 'id': 'call_B9GJUFfxFvHmLCotXuSMyYXn', 'type': 'tool_call'}\n",
            "Back to the model!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1. **Who won the Super Bowl in 2024?**\\n   - The Kansas City Chiefs won the Super Bowl in 2024, defeating the San Francisco 49ers 25-22 in overtime.\\n\\n2. **In what state is the winning team headquarters located?**\\n   - The Kansas City Chiefs' headquarters is located in Missouri.\\n\\n3. **What is the GDP of that state?**\\n   - The real GDP for Missouri in the 3rd quarter of 2023 was $52.8 billion for the real estate sector, which was the highest in the state. For a more comprehensive figure, the state's GDP would encompass all sectors, but specific data for the entire GDP for 2024 isn't provided in the available sources directly. However, the U.S. Bureau of Economic Analysis provides updates, and Missouri's economy has been growing at an annual rate of around 3.0 percent as of the second quarter of 2024.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class Agent:\n",
        "#     def __init__(self, system=\"\"):\n",
        "#         self.system = system\n",
        "#         self.messages = []\n",
        "#         if self.system:\n",
        "#             self.messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "#     def __call__(self, message):\n",
        "#         self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "#         result = self.execute()\n",
        "#         self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "#         return result\n",
        "\n",
        "#     def execute(self):\n",
        "#         completion = client.chat.completions.create(\n",
        "#                         model=\"gpt-4o\",\n",
        "#                         temperature=0,\n",
        "#                         messages=self.messages)\n",
        "#         return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "# def calculate(what):\n",
        "#     return eval(what)\n",
        "\n",
        "# def average_dog_weight(name):\n",
        "#     if name in \"Scottish Terrier\":\n",
        "#         return(\"Scottish Terriers average 20 lbs\")\n",
        "#     elif name in \"Border Collie\":\n",
        "#         return(\"a Border Collies average weight is 37 lbs\")\n",
        "#     elif name in \"Toy Poodle\":\n",
        "#         return(\"a toy poodles average weight is 7 lbs\")\n",
        "#     else:\n",
        "#         return(\"An average dog weights 50 lbs\")\n",
        "\n",
        "# known_actions = {\n",
        "#     \"calculate\": calculate,\n",
        "#     \"average_dog_weight\": average_dog_weight\n",
        "# }"
      ],
      "metadata": {
        "id": "RAFpmmqLmEpe"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action\n",
        "\n",
        "# def query(question, max_turns=5):\n",
        "#     i = 0\n",
        "#     bot = Agent(prompt)\n",
        "#     next_prompt = question\n",
        "#     while i < max_turns:\n",
        "#         i += 1\n",
        "#         result = bot(next_prompt)\n",
        "#         print(result)\n",
        "#         actions = [\n",
        "#             action_re.match(a)\n",
        "#             for a in result.split('\\n')\n",
        "#             if action_re.match(a)\n",
        "#         ]\n",
        "#         if actions:\n",
        "#             # There is an action to run\n",
        "#             action, action_input = actions[0].groups()\n",
        "#             if action not in known_actions:\n",
        "#                 raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
        "#             print(\" -- running {} {}\".format(action, action_input))\n",
        "#             observation = known_actions[action](action_input)\n",
        "#             print(\"Observation:\", observation)\n",
        "#             next_prompt = \"Observation: {}\".format(observation)\n",
        "#         else:\n",
        "#             return"
      ],
      "metadata": {
        "id": "5zyIWLO3okdP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
        "# What is their combined weight\"\"\"\n",
        "# query(question)"
      ],
      "metadata": {
        "id": "vo-YoXHaxSKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}